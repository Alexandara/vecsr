% EPTCS Style distribution v1.7.0 released May 23, 2022.
% https://github.com/EPTCS/style
\documentclass[submission,copyright]{eptcs}
\providecommand{\event}{ICLP/LPNMR-DC 2024} % Name of the event you are submitting to

\usepackage{iftex}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}

\lstdefinestyle{prolog}
{
    language=Prolog,
    basicstyle = \ttfamily\color{blue},
    moredelim = [s][\color{black}]{(}{)},
    literate =
        {:-}{{\textcolor{black}{:-}}}2
        {,}{{\textcolor{black}{,}}}1
        {.}{{\textcolor{black}{.}}}1,
    numbers=left,
    xleftmargin=2em,
    numberstyle=\tiny\color{gray}
}
\lstset{style=prolog}

\ifpdf
  \usepackage{underscore}         % Only needed if you use pdflatex.
  \usepackage[T1]{fontenc}        % Recommended with pdflatex
\else
  \usepackage{breakurl}           % Not needed if you use pdflatex only.
\fi

\title{s(CASP) Logic Programming for\\Autonomous Task Completion}
\author{Alexis Renee Tudor
\institute{University of Texas at Dallas\\Texas, USA}
\email{alexisrenee1@gmail.com}
}
\def\titlerunning{s(CASP) for Task Completion}
\def\authorrunning{A.R. Tudor}
\begin{document}
\maketitle

\begin{abstract}
Task planning for autonomous agents has typically been done using deep learning models and simulation-based reinforcement learning. This research proposes the use of s(CASP) inductive logic programming techniques to increase the explainability and reliability of these systems. Preliminary research has led to the creation ofbe augmented with reinforcement learning. Although this research is in the early stages, we are exploring solutions to complex problems in simulated task completion.
\end{abstract}

\section{Introduction}
Task planning for autonomous agents has been an area of interest in recent years as robotics and deep learning have made major advances. Most approaches to task planning involve the use of deep learning models. The most popular approach is deep reinforcement learning, though recent work has used large-language models (LLMs) as well. Deep learning models generally achieve good results, however, they are uninterpretable and often produce flawed answers with no explanation. Much work has been done in improving the explainability of deep learning models, however, they remain untrustworthy.

A better solution is to use logic programming, an approach that is inherently interpretable and easy to rectify incorrect answers. The research proposed in this paper involves using logic programming to complete tasks in a simulated environment. This will hopefully result in autonomous task planning that is both robust and trustworthy.

\section{Background and Relevant Literature}
As autonomous agents become more ubiquitous, the focus has turned to their ability to complete complex tasks in the real world, converting high-level instructions (like "fold laundry") to executable plans ("walk to clothes", "grab clothes", etc.). Autonomous task completion can mean anything from unmanned vehicles navigating from one point to another to robotic kitchen assistants designed to make certain foods. For the most part, modern autonomous systems use deep learning models to accomplish this\cite{Amiri2020}. This commonly takes the form of deep reinforcement learning and more recently LLMs. Deep learning has achieved very good results on complex problems. However, most deep learning systems are black boxes that lack explainability and interpretability. This is especially dangerous given how dependent deep learning algorithms are on the (often flawed) data they are trained on. This makes it difficult to trust that their answers are correct and unbiased, as explored in DARPA's explainable AI retrospective\cite{gunning2021}. This is important in critical systems, such as hospital diagnoses or military applications, where it has to be quickly apparent whether a model is correct or not. LLMs are vulnerable to "hallucination", where they provide incorrect responses that are statistically likely\cite{huang2023}. Additionally, they can be "jailbroken" to respond outside of the bounds they were designed for\cite{chao2023}. In the specific arena of autonomous task completion, LLMs struggle with making task breakdowns that are both correct and executable\cite{huang22}. Deep learning as a whole is well explained in other high-quality survey papers\cite{dong2021}. This paper will focus more on the importance of explainability, which is often neglected in deep learning models.

Inductive Logic Programming (ILP) is a form of machine learning that codifies its learning in the form of first-order logic. Ever since the term was defined in 1991\cite{muggleton1991} as the "intersection
of Logic Programming and Machine Learning", ILP has served to solve machine learning problems. ILP can get results rivaling deep learning models while being inherently interpretable and explainable\cite{zhang2023}. Recent advances in ILP, such as the FOLD family of algorithms\cite{wang2022se}, demonstrate that complex data can be represented in small logic programs using default rules. A more detailed description of default rules and the FOLD family of incremental learning algorithms can be found in the paper by Gupta et al.\cite{gupta2023}. The research mentioned above uses a type of logic programming called Answer Set Programming (ASP). Unlike Prolog-based logic programming, which generates a true or false answer for a queried predicate, ASP is used to generate all entailable rules from a knowledge base. This collection is called an answer set. This can be used to generate "multiple worlds" where different answer sets are true.

Traditional ASP, like in Clingo \cite{gebser2014}, executes an answer set program through the use of an SAT solver and grounding. Grounding involves the generation of the program with all variables substituted with literals in the program. A disadvantage of this approach is that grounding is not always guaranteed to be feasible, which can leave some programs with no ASP solution. The s(CASP) system \cite{arias2018} solves this problem by performing a top-down goal-oriented search which eliminates the need for grounding. This advantage makes s(CASP) well-suited to the representation of complex world states.

One of the biggest weaknesses of the ILP approach to solving problems is the need for background information and 'program templates'. Program templates are a layout of how the generated information should look in the context of the logic program. A domain expert is needed to provide this program template and explicitly logic program-based background knowledge for most ILP. Thus, for trivial examples, it would be just as easy to include the final found rules in the knowledge base at the start. Additionally, while ILP programs perform very well on data that can be represented in a logic program, logic programs have a difficult time representing complex data. These weaknesses can be overcome through the use of traditional machine learning algorithms to supplement a logic program. This approach increases explainability while utilizing the benefits of deep learning and other machine learning models, such as in the paper by Rajasekharan et al. that uses an s(CASP) knowledge base to constrain an LLM into providing more reliable results\cite{rajasekharan2023}. Other examples exist of using some form of knowledge base to improve deep learning algorithms\cite{uchendu2023}\cite{hao2023}, but the use of logic programming to augment other algorithms merits further exploration.

\section{Research}
The research outlined in this paper seeks to explore the use of an s(CASP) knowledge base for autonomous task completion in a simulated virtual environment. To test our system, we use the VirtualHome simulator (shown in Figure \ref{fig:vh}) as a playground for our s(CASP) agent to perform tasks in. VirtualHome allows for multiple agents to operate in a variety of simulated apartments, and provides a large database of high-level task breakdowns into step-by-step instructions. This simulation proved to be especially useful for our research because it has a "mid-level" control scheme. This means that we can give the agent commands like "grab remote" rather than dealing with the details of actual movement ("move left foot 3 inches forward", "rotate right arm 45 degrees at the elbow joint", etc) that would be more appropriate for a detailed robotic controller.

\begin{figure*}[htp]
\centering
\includegraphics[width = 300px]{virtualhome.png}
\caption{An image showcasing the VirtualHome simulator and an example of its associated task instructions\cite{puig2018}.}
\label{fig:vh}
\end{figure*}

\subsection{Goals}
The primary goal of this research is to achieve reasonably accurate task completion either with a fully s(CASP) solution or the combination of an s(CASP) knowledge base with a traditional machine learning model. The end system would have a high level of explainability for decision-making, where the results are trustworthy and could be diagnosed if in error. We wish to further prove that even the very high-quality deep learning systems in use today could be augmented through the use of logic programming. Using logic in this way moves towards true artificial intelligence. Using s(CASP) to simulate how humans can perform common-sense logical interactions with the world brings us closer to reasoning AI.

An additional goal of this research is to make s(CASP) easier to use with simulators. A notable weakness of s(CASP) is that it does not have a Python API, which makes it difficult to run in line with other forms of machine learning. The software engineering goal of this research is to make a "harness" for using s(CASP) in Python for interactions with simulators, as shown in Figure \ref{fig:pythonharness}.

\begin{figure*}[htp]
\centering
\fbox{\includegraphics[width = 300px]{PythonHarness.jpg}}
\caption{A diagram showing the functionality of the Python harness for s(CASP). The Python harness can perform actions in the VirtualHome environment, and then convert the state of the environment to s(CASP) facts. These facts can then be used to inform the next action of the agent.}
\label{fig:pythonharness}
\end{figure*}

\subsection{Status}
This research is still in an early stage, where the infrastructure surrounding the problem is complete and we can experiment with possible solutions. Using the Python harness mentioned above, we can instantiate an instance of the VirtualHome simulator and transform the world state into s(CASP):
\begin{lstlisting}
current_time(1).
type(livingroom100, livingroom).
type(remotecontrol1, remotecontrol).
off(remotecontrol1, 1).
inside(remotecontrol1, [livingroom100], 1).
\end{lstlisting}
The above example represents a world state containing a single turned-off remote control sitting in a living room at time 1. This representation of the world state can get very complex, encompassing a large amount of facts. Additionally, the harness can include s(CASP) state facts for previous times, greatly increasing the number of facts in the world. This has proved to be a computational obstacle. We currently use a small-scale simulation with only the needed items for certain tasks.

To represent and complete tasks, we have pursued two different s(CASP) templates for tasks. The current approach is similar to an s(CASP) solution for the Yale shooting problem, with a very constrained state as below\footnote{There are more predicates than included here, this is a small subset to convey the general idea.}:
\begin{lstlisting}
% Find Actions
holds(0,State,[]) :-
    init_holds_item(State).
holds(Time1, FinalState, [Action|As]) :-
    Time1 .>. 0, Time1 .=. Time + 1,
    allowed_action(Action, PrevState, Time1),
    transition(Action, PrevState, FinalState),
    holds(Time, PrevState, As).

init_holds_item(state(character0, Close, Held)) :-
                    current_time(T),
                    isclose(character0, Close, T),
                    held_by(character0, Held, T).

% State transitions
transition([grab, X], state(character0, Close, Held),
                      state(character0, Close, [X | Held])).

% Prohibited action conditions
prohibited([grab, X], _, T) :- not grabbable(X).

% Allowed Actions
allowed_action([grab, X], state(character0, Close, Held), T) :- grabbable(X), member(X, Close).

?- holds(T, state(character0, [remotecontrol1], [remotecontrol1]), List).
\end{lstlisting}

However, this solution does not work due to infinite execution over an infinite amount of time. Continuing research will be done on solving this as a planning problem, ignoring time for now.

\subsection{Open Issues and Expected Achievements}
Right now, the biggest issues facing this research concern the representation of the s(CASP) knowledge base. There are several outstanding questions.

\paragraph{Representing a Complex Real-World State} Representing a simulation of any reasonable size leads to an exponential increase in the number of facts available in the world state. In addition to these facts, there also needs to be a set of rules adequate to perform tasks in the environment. This produces answer sets that are intractable to generate. One solution that can be explored is to keep the state facts and rules in different programs. This follows the human logic that one likely does not need their cooking knowledge if, for example, they need to walk their dog.

\paragraph{The Passage of Time} As mentioned above, the use of time in the knowledge base provides complications related to the ostensibly infinitely divisible nature of time (as posited by the famous Greek philosopher Zeno). This is a known problem with logic programming and would require the inclusion of event calculus\cite{varanasi2022}.

\paragraph{Large Scale Learning} After the completion of a s(CASP) template that allows for action generation for task completion, the next question would be automation. How can we turn databases of task instructions (such as those provided by VirtualHome or ALFRED\cite{Shridhar2019}) automatically into tasks that can be completed with a generalized s(CASP) framework? And further, how then can we integrate traditional machine learning into it to improve the results?
\\
\\
We expect to be able to answer these questions in a unified way to facilitate task completion in complex environments using s(CASP).

\section{Conclusion}
In conclusion, this line of research could open up a broad number of solutions for challenging ILP problems. Simply creating a Python framework for the use of s(CASP) with simulated environments is an advancement for s(CASP), as it is currently lacking a Python API. Using the intersection of ILP and traditional machine learning is promising for improving the explainability and reliability of task-completing autonomous agents.

\nocite{*}
\bibliographystyle{eptcs}
\bibliography{generic}
\end{document}
